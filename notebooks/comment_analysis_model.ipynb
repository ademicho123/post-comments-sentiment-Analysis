{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc38b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1708118079466,
     "user": {
      "displayName": "Ademicho",
      "userId": "16016306917753753169"
     },
     "user_tz": 0
    },
    "id": "99fc38b1",
    "outputId": "a1f35bcf-86c1-416d-d842-2ee28574c68f"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Add project root to path for importing custom modules\n",
    "project_root = str(Path.cwd().parent) if 'notebooks' in str(Path.cwd()) else str(Path.cwd())\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Download required NLTK data\n",
    "import nltk\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac3bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First check if your preprocessing module is accessible\n",
    "import src.preprocessing\n",
    "print(dir(src.preprocessing))  # This will show all available functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3441ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the correct path to the data file\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == 'notebooks':\n",
    "    data_path = current_dir.parent / 'data' / 'raw' / 'comments_1st.csv'\n",
    "else:\n",
    "    data_path = current_dir / 'data' / 'raw' / 'comments_1st.csv'\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "print(f\"Attempting to load from: {data_path}\")\n",
    "data = pd.read_csv(str(data_path), encoding='Windows-1252', engine='python', on_bad_lines='skip', encoding_errors='replace')\n",
    "\n",
    "if data is not None:\n",
    "    print(\"\\nData loaded successfully!\")\n",
    "    print(\"Dataset Shape:\", data.shape)\n",
    "    print(\"\\nColumns:\", data.columns.tolist())\n",
    "    print(\"\\nMissing Values:\\n\", data.isnull().sum())\n",
    "else:\n",
    "    print(\"Failed to load data file.\")\n",
    "\n",
    "# Preview the data\n",
    "print(\"\\nFirst few rows of the data:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c260cc56",
   "metadata": {
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1708118080226,
     "user": {
      "displayName": "Ademicho",
      "userId": "16016306917753753169"
     },
     "user_tz": 0
    },
    "id": "c260cc56"
   },
   "outputs": [],
   "source": [
    "# Comment Length Analysis\n",
    "data['comment_length'] = data['comments'].str.len()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=data['comment_length'], bins=50)\n",
    "plt.title('Distribution of Comment Lengths')\n",
    "plt.xlabel('Comment Length')\n",
    "plt.ylabel('Count')\n",
    "reports_dir = os.path.join(project_root, 'reports')\n",
    "if not os.path.exists(reports_dir):\n",
    "    os.makedirs(reports_dir)\n",
    "plt.savefig(os.path.join(reports_dir, 'comment_length_distribution.png'))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40dd0465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis with VADER\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def assign_sentiment_scores(text):\n",
    "    scores = sia.polarity_scores(text)\n",
    "    return scores['compound']\n",
    "\n",
    "def assign_scores(data):\n",
    "    data['sentiment'] = data['comments'].apply(assign_sentiment_scores)\n",
    "    return data\n",
    "\n",
    "def assign_directions(data):\n",
    "    data['mood'] = data['sentiment'].apply(lambda x: 'negative' if x < 0.0 else ('neutral' if 0.0 <= x < 0.4 else 'positive'))\n",
    "    data['target'] = data['sentiment'].apply(lambda x: 2 if x < 0.0 else (1 if 0.0 <= x < 0.4 else 0))\n",
    "    return data\n",
    "\n",
    "# Assign sentiment scores and directions\n",
    "data = assign_scores(data)\n",
    "data = assign_directions(data)  # Call assign_directions before plotting\n",
    "\n",
    "# Plot histogram of sentiments\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=data, x='mood')  # Changed to countplot for categorical data\n",
    "plt.title('Distribution of Sentiment Categories')\n",
    "plt.xlabel('Sentiment Category')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig(os.path.join(reports_dir, 'sentiment_category_distribution.png'))\n",
    "plt.close()\n",
    "\n",
    "# Plot bar chart of sentiment categories\n",
    "sentiment_counts = data['target'].value_counts()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values)\n",
    "plt.title('Distribution of Sentiment Categories')\n",
    "plt.xlabel('Sentiment Category')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig(os.path.join(reports_dir, 'sentiment_category_distribution.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654fa26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's check the data types and structure\n",
    "print(\"Data info:\")\n",
    "print(data.info())\n",
    "\n",
    "print(\"\\nSample of comments column:\")\n",
    "print(data['comments'].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13581852",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 496,
     "status": "ok",
     "timestamp": 1708118080714,
     "user": {
      "displayName": "Ademicho",
      "userId": "16016306917753753169"
     },
     "user_tz": 0
    },
    "id": "13581852",
    "outputId": "e53e8ec0-bc0c-4b6b-a60e-4061af99c72c"
   },
   "outputs": [],
   "source": [
    "from preprocessing import preprocess_data \n",
    "\n",
    "# Preprocess the comments\n",
    "print(\"Preprocessing comments...\")\n",
    "data = preprocess_data(data)\n",
    "\n",
    "# Check the results\n",
    "print(\"\\nFirst few processed comments:\")\n",
    "print(data[['comments', 'processed_comments']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a2eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Processed Data\n",
    "print(\"\\nSaving processed data...\")\n",
    "processed_data_path = os.path.join(project_root, 'data', 'processed')\n",
    "if not os.path.exists(processed_data_path):\n",
    "    os.makedirs(processed_data_path)\n",
    "data.to_csv(os.path.join(processed_data_path, 'processed_data.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65459ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import prepare_dataset \n",
    "\n",
    "# Prepare data for training\n",
    "print(\"\\nPreparing dataset...\")\n",
    "X_train, X_test, y_train, y_test, vectorizer = prepare_dataset(data)\n",
    "\n",
    "# Verify dataset sizes\n",
    "print(\"\\nFirst few lines of training data:\")\n",
    "print(pd.DataFrame(y_train, columns=['target']).head())\n",
    "\n",
    "print(\"\\nClass distribution in training data:\")\n",
    "print(pd.DataFrame(y_train, columns=['target']).target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bda4962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train_model function\n",
    "from src.model import train_model\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining the XGBoost model...\")\n",
    "model = train_model(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "be2a808f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.25      1.00      0.40         5\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.25        20\n",
      "   macro avg       0.08      0.33      0.13        20\n",
      "weighted avg       0.06      0.25      0.10        20\n",
      "\n",
      "Accuracy: 0.25\n",
      "Error: evaluate_model function returned None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELITEBOOK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ELITEBOOK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ELITEBOOK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from src.model import evaluate_model\n",
    "from src.visualization import plot_confusion_matrix\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Evaluating the model...\")\n",
    "eval_results = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "# Check if eval_results is not None\n",
    "if eval_results is not None:\n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(y_test, eval_results['predictions'])\n",
    "    plt.savefig(os.path.join(reports_dir, 'confusion_matrix.png'))\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"Error: evaluate_model function returned None.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "775eade7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to c:\\Users\\ELITEBOOK\\OneDrive\\Desktop\\Projects\\post-comments-sentiment-Analysis\\models\\comment_sentiments_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model for later use\n",
    "model_dir = os.path.join(project_root, 'models')\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "model_path = os.path.join(model_dir, 'comment_sentiments_model.pkl')\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
