{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99fc38b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1708118079466,
     "user": {
      "displayName": "Ademicho",
      "userId": "16016306917753753169"
     },
     "user_tz": 0
    },
    "id": "99fc38b1",
    "outputId": "a1f35bcf-86c1-416d-d842-2ee28574c68f"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'prepare_dataset' from 'src.preprocessing' (c:\\Users\\ELITEBOOK\\OneDrive\\Desktop\\Projects\\post-comments-sentiment-Analysis\\src\\preprocessing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(project_root)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Import custom modules\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_data, preprocess_data, prepare_dataset\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_model, evaluate_model, save_model\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_confusion_matrix, plot_feature_importance\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'prepare_dataset' from 'src.preprocessing' (c:\\Users\\ELITEBOOK\\OneDrive\\Desktop\\Projects\\post-comments-sentiment-Analysis\\src\\preprocessing.py)"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Add project root to path for importing custom modules\n",
    "project_root = str(Path.cwd().parent) if 'notebooks' in str(Path.cwd()) else str(Path.cwd())\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import custom modules\n",
    "from src.preprocessing import load_data, preprocess_data, prepare_dataset\n",
    "from src.model import train_model, evaluate_model, save_model\n",
    "from src.visualization import plot_confusion_matrix, plot_feature_importance\n",
    "\n",
    "# Download required NLTK data\n",
    "import nltk\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab3441ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Attempting to load from: c:\\Users\\ELITEBOOK\\OneDrive\\Desktop\\Projects\\post-comments-sentiment-Analysis\\data\\raw\\comments_1st.csv\n",
      "\n",
      "Data loaded successfully!\n",
      "Dataset Shape: (1032, 11)\n",
      "\n",
      "Columns: ['Public Identifier', 'Profile Link', 'Full Name', 'Subtitle', 'Comment Url', 'comments', 'Like Count', 'Comment Count', 'Is Reply', 'Is Author', 'Comment Time']\n",
      "\n",
      "Missing Values:\n",
      " Public Identifier    0\n",
      "Profile Link         0\n",
      "Full Name            0\n",
      "Subtitle             1\n",
      "Comment Url          0\n",
      "comments             0\n",
      "Like Count           0\n",
      "Comment Count        0\n",
      "Is Reply             0\n",
      "Is Author            0\n",
      "Comment Time         0\n",
      "dtype: int64\n",
      "\n",
      "First few rows of the data:\n",
      "                         Public Identifier  \\\n",
      "0  ACoAAAArQoYBpAqYrKxJmm8d24JvmnPZJME8u8I   \n",
      "1  ACoAAAATB9sBQ4Lr1QH_HHcaU7nsv0veqUjG0iI   \n",
      "2  ACoAAAAsJKMBhXw2HY7b6BQcG5onjnxpSQusdaw   \n",
      "3  ACoAAAHNFVQBIa-Ul4NAml-iAqsZTAuZvqcGINw   \n",
      "4  ACoAAANmB6kBj8i-jq9oLr67NuxriLKmpuiH6CI   \n",
      "\n",
      "                                        Profile Link  \\\n",
      "0  https://www.linkedin.com/in/ACoAAAArQoYBpAqYrK...   \n",
      "1  https://www.linkedin.com/in/ACoAAAATB9sBQ4Lr1Q...   \n",
      "2  https://www.linkedin.com/in/ACoAAAAsJKMBhXw2HY...   \n",
      "3  https://www.linkedin.com/in/ACoAAAHNFVQBIa-Ul4...   \n",
      "4  https://www.linkedin.com/in/ACoAAANmB6kBj8i-jq...   \n",
      "\n",
      "                                     Full Name  \\\n",
      "0                                   Winnie Sun   \n",
      "1                               Marsha Collier   \n",
      "2                               Brett Gillilan   \n",
      "3                                Melissa Reyes   \n",
      "4  Dr. Ai Addyson-Zhang ?? Education Disruptor   \n",
      "\n",
      "                                            Subtitle  \\\n",
      "0  #WinnieSun ?? ?? 25+ billion impressions share...   \n",
      "1  47 books: eCommerce, Social Media, Customer Se...   \n",
      "2                                     B2B Consultant   \n",
      "3                   Operations Manager at CVS Health   \n",
      "4  ?? I help teens & young adults reclaim their c...   \n",
      "\n",
      "                                         Comment Url  \\\n",
      "0  https://www.linkedin.com/feed/update/urn:li:ac...   \n",
      "1  https://www.linkedin.com/feed/update/urn:li:ac...   \n",
      "2  https://www.linkedin.com/feed/update/urn:li:ac...   \n",
      "3  https://www.linkedin.com/feed/update/urn:li:ac...   \n",
      "4  https://www.linkedin.com/feed/update/urn:li:ac...   \n",
      "\n",
      "                                            comments  Like Count  \\\n",
      "0  Meeting Marsha Collier in person = priceless! ...           4   \n",
      "1  I figured you'd be working anyway. Thanks so m...           0   \n",
      "2  Do you have the ability to get a full length f...           0   \n",
      "3  Bummed I am just seeing this! Hope you had a f...           1   \n",
      "4  This is soooo awesome! Wish i could join you a...           1   \n",
      "\n",
      "   Comment Count  Is Reply  Is Author           Comment Time  \n",
      "0              4     False      False  5/23/2018, 2:22:04 AM  \n",
      "1              0      True       True  5/26/2018, 1:09:55 AM  \n",
      "2              0     False      False  5/23/2018, 6:08:14 PM  \n",
      "3              1     False      False  5/25/2018, 2:27:46 PM  \n",
      "4              0     False      False  5/23/2018, 6:50:21 AM  \n"
     ]
    }
   ],
   "source": [
    "# Determine the correct path to the data file\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == 'notebooks':\n",
    "    data_path = current_dir.parent / 'data' / 'raw' / 'comments_1st.csv'\n",
    "else:\n",
    "    data_path = current_dir / 'data' / 'raw' / 'comments_1st.csv'\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "print(f\"Attempting to load from: {data_path}\")\n",
    "data = pd.read_csv(str(data_path), encoding='Windows-1252', engine='python', on_bad_lines='skip', encoding_errors='replace')\n",
    "\n",
    "if data is not None:\n",
    "    print(\"\\nData loaded successfully!\")\n",
    "    print(\"Dataset Shape:\", data.shape)\n",
    "    print(\"\\nColumns:\", data.columns.tolist())\n",
    "    print(\"\\nMissing Values:\\n\", data.isnull().sum())\n",
    "else:\n",
    "    print(\"Failed to load data file.\")\n",
    "\n",
    "# Preview the data\n",
    "print(\"\\nFirst few rows of the data:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c260cc56",
   "metadata": {
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1708118080226,
     "user": {
      "displayName": "Ademicho",
      "userId": "16016306917753753169"
     },
     "user_tz": 0
    },
    "id": "c260cc56"
   },
   "outputs": [],
   "source": [
    "# Comment Length Analysis\n",
    "data['comment_length'] = data['comments'].str.len()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=data['comment_length'], bins=50)\n",
    "plt.title('Distribution of Comment Lengths')\n",
    "plt.xlabel('Comment Length')\n",
    "plt.ylabel('Count')\n",
    "reports_dir = os.path.join(project_root, 'reports')\n",
    "if not os.path.exists(reports_dir):\n",
    "    os.makedirs(reports_dir)\n",
    "plt.savefig(os.path.join(reports_dir, 'comment_length_distribution.png'))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40dd0465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis with VADER\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def assign_sentiment_scores(text):\n",
    "    scores = sia.polarity_scores(text)\n",
    "    return scores['compound']\n",
    "\n",
    "def assign_scores(data):\n",
    "    data['sentiment'] = data['comments'].apply(assign_sentiment_scores)\n",
    "    return data\n",
    "\n",
    "def assign_directions(data):\n",
    "    data['mood'] = data['sentiment'].apply(lambda x: 'negative' if x < 0.0 else ('neutral' if 0.0 <= x < 0.4 else 'positive'))\n",
    "    data['target'] = data['sentiment'].apply(lambda x: 2 if x < 0.0 else (1 if 0.0 <= x < 0.4 else 0))\n",
    "    return data\n",
    "\n",
    "# Assign sentiment scores and directions\n",
    "data = assign_scores(data)\n",
    "data = assign_directions(data)  # Call assign_directions before plotting\n",
    "\n",
    "# Plot histogram of sentiments\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=data, x='mood')  # Changed to countplot for categorical data\n",
    "plt.title('Distribution of Sentiment Categories')\n",
    "plt.xlabel('Sentiment Category')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig(os.path.join(reports_dir, 'sentiment_category_distribution.png'))\n",
    "plt.close()\n",
    "\n",
    "# Plot bar chart of sentiment categories\n",
    "sentiment_counts = data['target'].value_counts()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values)\n",
    "plt.title('Distribution of Sentiment Categories')\n",
    "plt.xlabel('Sentiment Category')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig(os.path.join(reports_dir, 'sentiment_category_distribution.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "654fa26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1032 entries, 0 to 1031\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Public Identifier  1032 non-null   object \n",
      " 1   Profile Link       1032 non-null   object \n",
      " 2   Full Name          1032 non-null   object \n",
      " 3   Subtitle           1031 non-null   object \n",
      " 4   Comment Url        1032 non-null   object \n",
      " 5   comments           1032 non-null   object \n",
      " 6   Like Count         1032 non-null   int64  \n",
      " 7   Comment Count      1032 non-null   int64  \n",
      " 8   Is Reply           1032 non-null   bool   \n",
      " 9   Is Author          1032 non-null   bool   \n",
      " 10  Comment Time       1032 non-null   object \n",
      " 11  comment_length     1032 non-null   int64  \n",
      " 12  sentiment          1032 non-null   float64\n",
      " 13  mood               1032 non-null   object \n",
      " 14  target             1032 non-null   int64  \n",
      "dtypes: bool(2), float64(1), int64(4), object(8)\n",
      "memory usage: 107.0+ KB\n",
      "None\n",
      "\n",
      "Sample of comments column:\n",
      "0    Meeting Marsha Collier in person = priceless! ...\n",
      "1    I figured you'd be working anyway. Thanks so m...\n",
      "Name: comments, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# First, let's check the data types and structure\n",
    "print(\"Data info:\")\n",
    "print(data.info())\n",
    "\n",
    "print(\"\\nSample of comments column:\")\n",
    "print(data['comments'].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13581852",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 496,
     "status": "ok",
     "timestamp": 1708118080714,
     "user": {
      "displayName": "Ademicho",
      "userId": "16016306917753753169"
     },
     "user_tz": 0
    },
    "id": "13581852",
    "outputId": "e53e8ec0-bc0c-4b6b-a60e-4061af99c72c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing comments...\n",
      "\n",
      "First few processed comments:\n",
      "                                            comments  \\\n",
      "0  Meeting Marsha Collier in person = priceless! ...   \n",
      "1  I figured you'd be working anyway. Thanks so m...   \n",
      "2  Do you have the ability to get a full length f...   \n",
      "3  Bummed I am just seeing this! Hope you had a f...   \n",
      "4  This is soooo awesome! Wish i could join you a...   \n",
      "\n",
      "                                  processed_comments  \n",
      "0  meeting marsha collier person priceless excite...  \n",
      "1             figured working anyway thanks much mel  \n",
      "2        ability get full length feature film funded  \n",
      "3                   bummed seeing hope fabulous time  \n",
      "4     soooo awesome wish could join awesome lady fun  \n"
     ]
    }
   ],
   "source": [
    "# Preprocess the comments\n",
    "print(\"Preprocessing comments...\")\n",
    "data = preprocess_data(data)\n",
    "\n",
    "# Check the results\n",
    "print(\"\\nFirst few processed comments:\")\n",
    "print(data[['comments', 'processed_comments']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5a2eee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving processed data...\n"
     ]
    }
   ],
   "source": [
    "# Save Processed Data\n",
    "print(\"\\nSaving processed data...\")\n",
    "processed_data_path = os.path.join(project_root, 'data', 'processed')\n",
    "if not os.path.exists(processed_data_path):\n",
    "    os.makedirs(processed_data_path)\n",
    "data.to_csv(os.path.join(processed_data_path, 'processed_data.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65459ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prepare_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Prepare data for training\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSplitting data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m X_train, X_test, y_train, y_test, vectorizer \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_dataset\u001b[49m(data)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Print a few lines of the data\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFirst few lines of training data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prepare_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Prepare data for training\n",
    "print(\"\\nSplitting data...\")\n",
    "X_train, X_test, y_train, y_test, vectorizer = prepare_dataset(data)\n",
    "\n",
    "# Print a few lines of the data\n",
    "print(\"\\nFirst few lines of training data:\")\n",
    "print(pd.DataFrame(y_train, columns=['target']).head())\n",
    "\n",
    "# Print class distribution\n",
    "print(\"\\nClass distribution:\")\n",
    "print(pd.DataFrame(y_train, columns=['target']).target.value_counts())\n",
    "\n",
    "# Print a classification report\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_train, y_train))\n",
    "\n",
    "# Print a confusion matrix\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix(y_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bda4962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "print(\"\\nTraining model...\")\n",
    "model = train_model(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "print(\"\\nEvaluating model...\")\n",
    "evaluate_model(model, X_test, y_test)\n",
    "\n",
    "# Generate Visualizations\n",
    "print(\"\\nGenerating visualizations...\")\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(y_test, model.predict(X_test), labels=['Negative', 'Positive'])\n",
    "plt.savefig('reports/confusion_matrix.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70688bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "feature_names = ['comment_length', 'compound', 'pos', 'neu', 'neg']\n",
    "plot_feature_importance(model, feature_names, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775eade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "print(\"\\nSaving model...\")\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "save_model(model, 'models/comment_sentiments_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
